{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import math"
      ],
      "metadata": {
        "id": "LH5Z9E4kdGZo"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load datasets\n",
        "train_df = pd.read_csv('training.data', header=None, na_values='?')\n",
        "test_df = pd.read_csv('test.data', header=None, na_values='?')\n",
        "\n",
        "# Define column names\n",
        "columns = [f'A{i}' for i in range(1, 16)] + ['A16']\n",
        "train_df.columns = columns\n",
        "test_df.columns = columns\n",
        "\n",
        "# Identify categorical and continuous attributes\n",
        "categorical_attrs = ['A1', 'A4', 'A5', 'A6', 'A7', 'A9', 'A10', 'A12', 'A13']\n",
        "continuous_attrs = ['A2', 'A3', 'A8', 'A11', 'A14', 'A15']\n",
        "\n",
        "# Handle missing values\n",
        "def handle_missing_values(train_data, test_data):\n",
        "    medians = {}\n",
        "    for attr in train_data.columns[:-1]:\n",
        "        if attr in categorical_attrs:\n",
        "            valid_values = train_data[attr].dropna().sort_values()\n",
        "            medians[attr] = valid_values.iloc[len(valid_values) // 2]\n",
        "        else:\n",
        "            medians[attr] = train_data[attr].median()\n",
        "    for attr in train_data.columns[:-1]:\n",
        "        train_data[attr] = train_data[attr].fillna(medians[attr])\n",
        "        test_data[attr] = test_data[attr].fillna(medians[attr])\n",
        "    return train_data, test_data\n",
        "\n",
        "train_df, test_df = handle_missing_values(train_df, test_df)\n",
        "\n",
        "# Convert to numpy arrays for efficiency\n",
        "train_data = train_df.to_numpy()\n",
        "test_data = test_df.to_numpy()\n",
        "attribute_indices = {col: i for i, col in enumerate(columns)}"
      ],
      "metadata": {
        "id": "SJy_Oxb5dJRY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entropy calculation\n",
        "def entropy(labels):\n",
        "    if len(labels) == 0:\n",
        "        return 0\n",
        "    counts = np.bincount(np.where(labels == '+', 1, 0))\n",
        "    probs = counts / len(labels)\n",
        "    return -np.sum([p * math.log2(p) for p in probs if p > 0])\n",
        "\n",
        "# Plurality value\n",
        "def plurality_value(labels):\n",
        "    if len(labels) == 0:\n",
        "        return '+'\n",
        "    return '+' if np.sum(labels == '+') >= np.sum(labels == '-') else '-'\n",
        "\n",
        "# Accuracy calculation\n",
        "def accuracy(true_labels, pred_labels):\n",
        "    return np.mean(true_labels == pred_labels)\n",
        "\n",
        "# F1 Score calculation\n",
        "def f1_score(true_labels, pred_labels):\n",
        "    tp = np.sum((true_labels == '+') & (pred_labels == '+'))\n",
        "    fp = np.sum((true_labels == '-') & (pred_labels == '+'))\n",
        "    fn = np.sum((true_labels == '+') & (pred_labels == '-'))\n",
        "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    return 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0"
      ],
      "metadata": {
        "id": "BffFLlBgdLEz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Precompute unique values for efficiency\n",
        "def precompute_values(data, attr_idx):\n",
        "    return np.unique(data[:, attr_idx])\n",
        "\n",
        "# Information Gain with precomputed values\n",
        "def information_gain(data, attr_idx, label_idx):\n",
        "    total_entropy = entropy(data[:, label_idx])\n",
        "    values = precompute_values(data, attr_idx)\n",
        "    weighted_entropy = 0\n",
        "    for value in values:\n",
        "        subset = data[data[:, attr_idx] == value]\n",
        "        weighted_entropy += len(subset) / len(data) * entropy(subset[:, label_idx])\n",
        "    return total_entropy - weighted_entropy\n",
        "\n",
        "# Gain Ratio (C4.5)\n",
        "def gain_ratio(data, attr_idx, label_idx):\n",
        "    gain = information_gain(data, attr_idx, label_idx)\n",
        "    values = precompute_values(data, attr_idx)\n",
        "    intrinsic_value = -sum(len(data[data[:, attr_idx] == v]) / len(data) *\n",
        "                           math.log2(len(data[data[:, attr_idx] == v]) / len(data))\n",
        "                           for v in values)\n",
        "    return gain / intrinsic_value if intrinsic_value > 0 else 0\n",
        "\n",
        "# Gini Index (CART)\n",
        "def gini_index(data, attr_idx, label_idx):\n",
        "    values = precompute_values(data, attr_idx)\n",
        "    weighted_gini = 0\n",
        "    for value in values:\n",
        "        subset = data[data[:, attr_idx] == value]\n",
        "        if len(subset) == 0:\n",
        "            continue\n",
        "        counts = np.bincount(np.where(subset[:, label_idx] == '+', 1, 0), minlength=2)\n",
        "        probs = counts / len(subset)\n",
        "        gini = 1 - np.sum(probs ** 2)\n",
        "        weighted_gini += len(subset) / len(data) * gini\n",
        "    return weighted_gini"
      ],
      "metadata": {
        "id": "e522pFScdMYC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimized best split for continuous attributes\n",
        "def best_split(data, attr_idx, label_idx):\n",
        "    values = np.sort(np.unique(data[:, attr_idx].astype(float)))\n",
        "    if len(values) < 2:\n",
        "        return -float('inf'), None\n",
        "    midpoints = (values[:-1] + values[1:]) / 2\n",
        "    best_gain = -float('inf')\n",
        "    best_split_point = None\n",
        "    labels = data[:, label_idx]\n",
        "    total_entropy = entropy(labels)\n",
        "\n",
        "    for midpoint in midpoints:\n",
        "        left_mask = data[:, attr_idx].astype(float) <= midpoint\n",
        "        left_labels = labels[left_mask]\n",
        "        right_labels = labels[~left_mask]\n",
        "        if len(left_labels) < 2 or len(right_labels) < 2:  # Minimum split size\n",
        "            continue\n",
        "        gain = total_entropy - (len(left_labels) / len(labels) * entropy(left_labels) +\n",
        "                                len(right_labels) / len(labels) * entropy(right_labels))\n",
        "        if gain > best_gain:\n",
        "            best_gain = gain\n",
        "            best_split_point = midpoint\n",
        "    return best_gain if best_gain != -float('inf') else -float('inf'), best_split_point"
      ],
      "metadata": {
        "id": "gpBGv_bjdNt4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Node:\n",
        "    def __init__(self, attribute=None, value=None, label=None, branches=None):\n",
        "        self.attribute = attribute\n",
        "        self.value = value\n",
        "        self.label = label\n",
        "        self.branches = branches or {}"
      ],
      "metadata": {
        "id": "RfyEiXPBdOx_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decision_tree_learning(data, attributes, parent_data, importance_func, max_depth=10, min_gain=0.01, depth=0):\n",
        "    labels = data[:, -1]\n",
        "    if len(data) < 2 or depth >= max_depth:\n",
        "        return Node(label=plurality_value(labels))\n",
        "    if np.all(labels == labels[0]):\n",
        "        return Node(label=labels[0])\n",
        "    if not attributes:\n",
        "        return Node(label=plurality_value(labels))\n",
        "\n",
        "    label_idx = attribute_indices['A16']\n",
        "    if importance_func == gain_ratio:\n",
        "        default_value = -float('inf')\n",
        "        best_attr = max(attributes, key=lambda a: gain_ratio(data, attribute_indices[a], label_idx) if a in categorical_attrs\n",
        "                        else best_split(data, attribute_indices[a], label_idx)[0])\n",
        "        best_score = (gain_ratio(data, attribute_indices[best_attr], label_idx) if best_attr in categorical_attrs\n",
        "                      else best_split(data, attribute_indices[best_attr], label_idx)[0])\n",
        "    else:  # CART\n",
        "        default_value = float('inf')\n",
        "        best_attr = min(attributes, key=lambda a: gini_index(data, attribute_indices[a], label_idx) if a in categorical_attrs\n",
        "                        else best_split(data, attribute_indices[a], label_idx)[0])\n",
        "        best_score = (gini_index(data, attribute_indices[best_attr], label_idx) if best_attr in categorical_attrs\n",
        "                      else best_split(data, attribute_indices[best_attr], label_idx)[0])\n",
        "\n",
        "    if best_score <= min_gain or (best_attr in continuous_attrs and best_split(data, attribute_indices[best_attr], label_idx)[1] is None):\n",
        "        return Node(label=plurality_value(labels))\n",
        "\n",
        "    attr_idx = attribute_indices[best_attr]\n",
        "    tree = Node(attribute=best_attr)\n",
        "    if best_attr in continuous_attrs:\n",
        "        gain, split_point = best_split(data, attr_idx, label_idx)\n",
        "        tree.value = split_point\n",
        "        left_mask = data[:, attr_idx].astype(float) <= split_point\n",
        "        tree.branches['<='] = decision_tree_learning(data[left_mask], [a for a in attributes if a != best_attr],\n",
        "                                                     data, importance_func, max_depth, min_gain, depth + 1)\n",
        "        tree.branches['>'] = decision_tree_learning(data[~left_mask], [a for a in attributes if a != best_attr],\n",
        "                                                    data, importance_func, max_depth, min_gain, depth + 1)\n",
        "    else:\n",
        "        values = precompute_values(data, attr_idx)\n",
        "        for value in values:\n",
        "            subset = data[data[:, attr_idx] == value]\n",
        "            if len(subset) > 0:\n",
        "                tree.branches[value] = decision_tree_learning(subset, [a for a in attributes if a != best_attr],\n",
        "                                                              data, importance_func, max_depth, min_gain, depth + 1)\n",
        "\n",
        "    return tree"
      ],
      "metadata": {
        "id": "SwGai5bKdPyb"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(tree, example):\n",
        "    if tree.label is not None:\n",
        "        return tree.label\n",
        "    attr_idx = attribute_indices[tree.attribute]\n",
        "    if tree.attribute in continuous_attrs:\n",
        "        return predict(tree.branches['<='], example) if float(example[attr_idx]) <= tree.value else predict(tree.branches['>'], example)\n",
        "    value = example[attr_idx]\n",
        "    return predict(tree.branches[value], example) if value in tree.branches else plurality_value(train_data[:, -1])"
      ],
      "metadata": {
        "id": "7j2F5NLEdRD_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_validation(data, importance_func):\n",
        "    fold_size = 55\n",
        "    folds = [data[i:i + fold_size] for i in range(0, len(data), fold_size)]\n",
        "    acc_scores, f1_scores = [], []\n",
        "\n",
        "    for i in range(10):\n",
        "        val_fold = folds[i]\n",
        "        train_folds = np.concatenate([folds[j] for j in range(10) if j != i])\n",
        "        tree = decision_tree_learning(train_folds, columns[:-1], train_folds, importance_func)\n",
        "        true_labels = val_fold[:, -1]\n",
        "        pred_labels = np.array([predict(tree, ex) for ex in val_fold])\n",
        "        acc_scores.append(accuracy(true_labels, pred_labels))\n",
        "        f1_scores.append(f1_score(true_labels, pred_labels))\n",
        "\n",
        "    return np.mean(acc_scores), np.mean(f1_scores), tree"
      ],
      "metadata": {
        "id": "ifJcFCi0dSJB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main execution//\n",
        "print(\"Running C4.5...\")\n",
        "c4_5_acc, c4_5_f1, c4_5_tree = cross_validation(train_data, gain_ratio)\n",
        "print(f\"C4.5 Cross-Validation Accuracy: {c4_5_acc:.4f}\")\n",
        "print(f\"C4.5 Cross-Validation F1 Score: {c4_5_f1:.4f}\")\n",
        "\n",
        "print(\"\\nRunning CART...\")\n",
        "cart_acc, cart_f1, cart_tree = cross_validation(train_data, gini_index)\n",
        "print(f\"CART Cross-Validation Accuracy: {cart_acc:.4f}\")\n",
        "print(f\"CART Cross-Validation F1 Score: {cart_f1:.4f}\")\n",
        "\n",
        "# Select best model based on F1 score\n",
        "best_tree = c4_5_tree if c4_5_f1 > cart_f1 else cart_tree\n",
        "best_model = \"C4.5\" if c4_5_f1 > cart_f1 else \"CART\"\n",
        "test_true_labels = test_data[:, -1]\n",
        "test_pred_labels = np.array([predict(best_tree, ex) for ex in test_data])\n",
        "test_acc = accuracy(test_true_labels, test_pred_labels)\n",
        "test_f1 = f1_score(test_true_labels, test_pred_labels)\n",
        "\n",
        "print(f\"\\nBest Model: {best_model}\")\n",
        "print(f\"Test Set Accuracy: {test_acc:.4f}\")\n",
        "print(f\"Test Set F1 Score: {test_f1:.4f}\")\n",
        "\n",
        "# Comparison\n",
        "print(\"\\nComparison of C4.5 and CART:\")\n",
        "print(f\"C4.5 - Accuracy: {c4_5_acc:.4f}, F1: {c4_5_f1:.4f}\")\n",
        "print(f\"CART - Accuracy: {cart_acc:.4f}, F1: {cart_f1:.4f}\")\n",
        "print(f\"Test Set - Accuracy: {test_acc:.4f}, F1: {test_f1:.4f} with {best_model}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASV76xIadTEN",
        "outputId": "1a17d179-83d9-4e33-8dc5-2042bcf220ff"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running C4.5...\n",
            "C4.5 Cross-Validation Accuracy: 0.8145\n",
            "C4.5 Cross-Validation F1 Score: 0.7791\n",
            "\n",
            "Running CART...\n",
            "CART Cross-Validation Accuracy: 0.7636\n",
            "CART Cross-Validation F1 Score: 0.7298\n",
            "\n",
            "Best Model: C4.5\n",
            "Test Set Accuracy: 0.8143\n",
            "Test Set F1 Score: 0.7969\n",
            "\n",
            "Comparison of C4.5 and CART:\n",
            "C4.5 - Accuracy: 0.8145, F1: 0.7791\n",
            "CART - Accuracy: 0.7636, F1: 0.7298\n",
            "Test Set - Accuracy: 0.8143, F1: 0.7969 with C4.5\n"
          ]
        }
      ]
    }
  ]
}